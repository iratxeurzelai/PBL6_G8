{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUTRITION DATASET AURREPROZESAKETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (Temp/ipykernel_12232/274680970.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\8orja\\AppData\\Local\\Temp/ipykernel_12232/274680970.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    data = pd.read_csv('C:\\Users\\8orja\\OneDrive\\Escritorio\\3.maila\\2.Cuatri\\PBL6\\Adimen\\epi_r.csv')\u001b[0m\n\u001b[1;37m                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('C:\\Users\\8orja\\OneDrive\\Escritorio\\3.maila\\2.Cuatri\\PBL6\\Adimen\\epi_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar y eliminar datos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = data.duplicated()\n",
    "print('Number of duplicate rows = %d' % (dups.sum()))\n",
    "\n",
    "print('Number of rows before discarding duplicates = %d' % (data.shape[0]))\n",
    "data = data.drop_duplicates()\n",
    "print('Number of rows after discarding duplicates = %d' % (data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento de los NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos las filas que no tengan calorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['calories'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al borrar los NaNs de calorias podemos ver que la mayoria de NaNs se han ido. Esto se debe a que no eran recetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, almacenaremos en otra variable los NaNs restantes de proteinas, y veremos que contienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls=data[data['protein'].isnull()]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo el resultado, hemos visto que la mayoría eran recetas que no nos interesan. Como 5 Simple Syropes, que encima tenian 0 calorias. Debido a esto tambien borraremos estos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['protein'].notna()]\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ahora qudan unos pocos NaNs en \"fat\". Así que miraremos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls=data[data['fat'].isnull()]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando el resultado, se observa que la mayoría son cocteles y más sirope. Y muchos de ellos tienen 0 proteinas. Así que tambien los borraremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['fat'].notna()]\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente nos queda un solo NaN en sodio, podemos ver que este tambien tiene 0 en protein y fat, y al ser encima una sola fila, la nborraremos tambien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls=data[data['sodium'].isnull()]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['sodium'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez limpiado los NaNs vamos a buscar filas que tengan 0 en los atributos fat, sodium, calories y proteinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = data[data[\"calories\"] == 0]\n",
    "zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 5 filas que no tienen calorias, no tiene sentido que una comida tenga 0 calorías, además son pocas. Borraremos estas 5 filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"calories\"] != 0]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerosProtein = data[data[\"protein\"] == 0]\n",
    "zerosProtein.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerosFat =  data[data[\"fat\"] == 0]\n",
    "zerosFat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroAmbos = data[(data['fat'] == 0) & (data['protein'] == 0) ]\n",
    "zeroAmbos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroSodium = data[data[\"sodium\"]==0]\n",
    "zeroSodium.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los resultados hemos decidido borrar los que tengan sodio 0 y los que tengan 0 en proteinas y grasa a la vez, ya que estas filas no son recetas que nos interesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(zeroAmbos.index,axis=0, inplace=True)\n",
    "#cargamos zerosodium otra vez porque si no da error porque algunos valores ya han sido borrados\n",
    "zeroSodium = data[data[\"sodium\"]==0]\n",
    "data.drop(zeroSodium.index,axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a borrar las filas que contengan un 1 en las columnas drink y alcoholic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebidas=data[(data['alcoholic'] == 1) | (data['drink'] == 1) | (data['drinks'] == 1) | (data['cake'] == 1)]\n",
    "bebidas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(bebidas.index,axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unificación de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar a ver si columnas como cheese y cheedar estan relacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheeseColumns = data[['cheese','cheddar']]\n",
    "cheeseColumns =  cheeseColumns[cheeseColumns['cheddar']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheeseColumns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitColumns = data[['fruit','apple']]\n",
    "fruitColumns =  fruitColumns[fruitColumns['apple']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitColumns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat = data[['meat']]\n",
    "meat =  meat[meat['meat']==1]\n",
    "meat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay relacion entre las variables genericas y las especificas así que crearemos unas columnas genericas y borraremos las demas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificador(row, datos):\n",
    "    columnas = datos.columns\n",
    "\n",
    "    i = 0\n",
    "    end = len(columnas)\n",
    "\n",
    "    for c in columnas:\n",
    "        if row[c] == 1:\n",
    "            return 1\n",
    "        i=i+1\n",
    "        if i >= end:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetear el index, recomendable para iterar\n",
    "data = data.reset_index()\n",
    "#creamos un dataframe vacio\n",
    "dataFinal = pd.DataFrame()\n",
    "dataFinal = pd.concat((dataFinal,data[['title', 'calories', 'protein', 'fat', 'sodium']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos por unificar las columnas que tienen que ver con si la receta tiene huevos o no, y crearemos una sola columna llamada \"huevos\" la cual añadiremos al nuevo DataFrame \"dataFinal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir columnas a unificar\n",
    "columnas = ['egg','egg nog', 'eggplant', 'omelet', 'mayonnaise']\n",
    "\n",
    "#crear un dataset solo con esas columnas\n",
    "eggsDatos =  data[columnas]\n",
    "\n",
    "#columnaEggs = codificador(eggsDatos)\n",
    "#data['huevos'] = data.apply(columnaEggs, axis=1)\n",
    "#data = pd.concat((data,columnaEggs), axis=1)\n",
    "\n",
    "#añadimos al dataFrame final la columna huevos y le asociamos los valores que devuelva la funcion codificador\n",
    "dataFinal['huevos']=data.apply(lambda row: codificador(row,eggsDatos), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que se ha creado correctamente un dataset unicamente con la columna \"huevos\" en la cual tiene los valores 1 o 0 dependiendo de si tiene o no huevos la receta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fruta\n",
    "columnas = ['apple','apple juice','banana','cherry','coconut','fruit','fruit juice','grapefruit','kiwi','cranberry','cranberry sauce',\n",
    "'macadamia nut','mango','melon','nectarine','orange','papaya','peach','pear','pineapple','plantain','plum','pomegranate','raspberry','strawberry',\n",
    "'tamarind','tropical fruit','watermelon']\n",
    "frutasDatos = data[columnas]\n",
    "dataFinal['frutas'] = data.apply(lambda row: codificador(row,frutasDatos), axis=1)\n",
    "\n",
    "#mariscos\n",
    "columnas = ['lobster','mussel', 'octopus', 'oyster', 'salmon', 'sardine', 'seafood', 'shellfish', 'shrimp', 'swordfish', 'trout', \n",
    "'tuna', 'caviar','crab','clam', 'fish']\n",
    "mariscosDatos = data[columnas]\n",
    "dataFinal['marisco'] = data.apply(lambda row: codificador(row,mariscosDatos), axis=1)\n",
    "\n",
    "#lacteos\n",
    "columnas = ['macaroni and cheese','milk/cream', 'mozzarella', 'parmesan', 'ricotta', 'sour cream', 'swiss cheese', 'yogurt',\n",
    " 'blue cheese', 'buttermilk', 'cheddar', 'cheese', 'cottage cheese','feta','goat cheese', 'cream cheese','custard']\n",
    "lacteosDatos = data[columnas]\n",
    "dataFinal['lacteos'] = data.apply(lambda row: codificador(row,lacteosDatos), axis=1)\n",
    "\n",
    "#frutos secos\n",
    "columnas = ['nut','nutmeg','peanut','peanut butter','pecan','pistachio','walnut', 'butternut squash','chestnut',\n",
    "'dried fruit','hazelnut','cashew']\n",
    "frutossecosDatos = data[columnas]\n",
    "dataFinal['frutos secos'] = data.apply(lambda row: codificador(row,frutossecosDatos), axis=1)\n",
    "\n",
    "#verduras\n",
    "columnas = ['broccoli','broccoli rabe','carrot','celery','leek','mushroom','pea','poblano', 'potato','pumpkin','radicchio',\n",
    "'radish','root vegetable','shallot','spinach','tomatillo','tomato','turnip']\n",
    "verdurasDatos = data[columnas]\n",
    "dataFinal['verduras'] = data.apply(lambda row: codificador(row,verdurasDatos), axis=1)  \n",
    "\n",
    "#legymbres\n",
    "columnas = ['chickpea','legume']\n",
    "legumbresDatos = data[columnas]\n",
    "dataFinal['legumbres'] = data.apply(lambda row: codificador(row,legumbresDatos), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar los datos limpios en un nuevo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFinal.to_csv('Recetas_procesadas.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
